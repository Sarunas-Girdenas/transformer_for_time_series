{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "import configparser\n",
    "from ast import literal_eval\n",
    "from hiko.dask import daskify\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from torch import nn\n",
    "\n",
    "# Read in config\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../ml_models_for_airflow/dbs3_config.ini')\n",
    "\n",
    "db_engine = create_engine(config['AIRFLOW']['postgres_conn'])\n",
    "\n",
    "pairs_mapping = literal_eval(config['MODEL']['pairs_mapping'])\n",
    "pairs = tuple(pairs_mapping.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_data_loader import Dataset\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_set = Dataset(config_location='../ml_models_for_airflow/dbs3_config.ini',\n",
    "                      pairs=pairs,\n",
    "                      seq_lenght=16,\n",
    "                      num_features=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_size = int(len(full_data_set)*0.85)\n",
    "test_set_size = len(full_data_set) - train_set_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, valset = data.random_split(full_data_set,\n",
    "                                     [train_set_size, test_set_size]\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.LogSoftmax + nn.NLLLoss -> to get probabilities, call `torch.exp` on the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = data.DataLoader(trainset, batch_size=256, shuffle=True, num_workers=2)\n",
    "test_generator = data.DataLoader(valset, batch_size=256, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(emb=16,\n",
    "                          heads=4,\n",
    "                          depth=15,\n",
    "                          num_classes=2,\n",
    "                          num_features=3,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(transformer.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.NLLLoss()\n",
    "track_epoch_loss = []\n",
    "train_auc = []\n",
    "test_auc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ep in range(NUM_EPOCHS):\n",
    "    transformer.train()\n",
    "    epoch_loss = 0\n",
    "    temp_train_auc = 0\n",
    "    \n",
    "    for train_x, train_y in train_generator:\n",
    "        \n",
    "        predictions = transformer(train_x)\n",
    "        loss = criterion(predictions, train_y)\n",
    "        epoch_loss += loss.item()\n",
    "        temp_train_auc += roc_auc_score(\n",
    "            train_y.numpy(), torch.exp(predictions)[:, 1].detach().numpy())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_auc.append(temp_train_auc/len(train_generator))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        transformer.eval()\n",
    "        temp_test_auc = 0\n",
    "        for test_x, test_y in test_generator:\n",
    "            predictions = transformer(test_x)\n",
    "            temp_test_auc += roc_auc_score(\n",
    "                test_y.numpy(), torch.exp(predictions)[:, 1].numpy())\n",
    "\n",
    "    test_auc.append(temp_test_auc/len(test_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5729353295300637,\n",
       " 0.5311213405315087,\n",
       " 0.5393249237158102,\n",
       " 0.5527567793002857,\n",
       " 0.5686866319387328,\n",
       " 0.5078949093791763,\n",
       " 0.5138536078742745,\n",
       " 0.559761183018957,\n",
       " 0.5663652857967711,\n",
       " 0.5226827670239378,\n",
       " 0.49532188938134336,\n",
       " 0.5753014656307325,\n",
       " 0.5598566189462908,\n",
       " 0.6023852937244736,\n",
       " 0.546432449080692,\n",
       " 0.5537755675388929,\n",
       " 0.553190345581519,\n",
       " 0.5539563941952396,\n",
       " 0.5090521893967899,\n",
       " 0.5415658797805475]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_auc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pp37",
   "language": "python",
   "name": "pp37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
